# üß† Fluxo de treino de uma LLM/SML

## üóÑÔ∏è Prepara√ß√£o do Dataset

* Coletar um grande conjunto de dados de texto (e.g. livros, artigos, etc.)
* Preparar o dataset para treinamento (e.g. tokeniza√ß√£o, remo√ß√£o de stop words, normaliza√ß√£o de frequ√™ncia, etc.)
* Dividir o dataset em conjuntos de treinamento, valida√ß√£o e teste

Aqui quero deixar um exemplo de um ficheiro formato json que pedi ao ChatGPT para fazer com dados sobre futebol Portugu√™s.
Como podemos verificar √© possivel usar as j√° existentes AIs para 'preparar' dados para fazermos o nosso proprio modelo.

```
da-me um exemplo de um ficheiro json com dados sobre futebol portugues, n√£o precisa ser muito grande ,
so com 20 linhas , para usar como dataset para um ML
```

```
Claro! Aqui est√° um exemplo de um ficheiro JSON com dados sobre futebol portugu√™s, adequado para uso como
dataset para Machine Learning:
[
    {
        "nome": "Benfica",
        "cidade": "Lisboa",
        "fundacao": 1904,
        "titulos_liga": 37,
        "estadio": "Est√°dio da Luz",
        "capacidade": 64642
    },
    {
        "nome": "Porto",
        "cidade": "Porto",
        "fundacao": 1893,
        "titulos_liga": 30,
        "estadio": "Est√°dio do Drag√£o",
        "capacidade": 50033
    },
    {
        "nome": "Sporting",
        "cidade": "Lisboa",
        "fundacao": 1906,
        "titulos_liga": 19,
        "estadio": "Est√°dio Jos√© Alvalade",
        "capacidade": 50095
    },
    {
        "nome": "Braga",
        "cidade": "Braga",
        "fundacao": 1921,
        "titulos_liga": 0,
        "estadio": "Est√°dio Municipal de Braga",
        "capacidade": 30286
    },
    {
        "nome": "Vit√≥ria de Guimar√£es",
        "cidade": "Guimar√£es",
        "fundacao": 1922,
        "titulos_liga": 0,
        "estadio": "Est√°dio D. Afonso Henriques",
        "capacidade": 30008
    },
    {
        "nome": "Boavista",
        "cidade": "Porto",
        "fundacao": 1903,
        "titulos_liga": 1,
        "estadio": "Est√°dio do Bessa",
        "capacidade": 28263
    },
    {
        "nome": "Mar√≠timo",
        "cidade": "Funchal",
        "fundacao": 1910,
        "titulos_liga": 0,
        "estadio": "Est√°dio dos Barreiros",
        "capacidade": 10932
    },
    {
        "nome": "Belenenses",
        "cidade": "Lisboa",
        "fundacao": 1919,
        "titulos_liga": 1,
        "estadio": "Est√°dio do Restelo",
        "capacidade": 19500
    },
    {
        "nome": "Pa√ßos de Ferreira",
        "cidade": "Pa√ßos de Ferreira",
        "fundacao": 1950,
        "titulos_liga": 0,
        "estadio": "Est√°dio da Mata Real",
        "capacidade": 9125
    },
    {
        "nome": "Rio Ave",
        "cidade": "Vila do Conde",
        "fundacao": 1939,
        "titulos_liga": 0,
        "estadio": "Est√°dio dos Arcos",
        "capacidade": 12815
    }
]
Este exemplo cont√©m informa√ß√µes b√°sicas sobre 10 clubes de futebol portugueses, incluindo nome,
cidade, ano de funda√ß√£o, t√≠tulos da liga, est√°dio e capacidade do est√°dio. √â um dataset simples
mas √∫til para come√ßar a explorar modelos de Machine Learning.
```

A quantidade de dados que voc√™ usa para treinar um modelo de ML pode influenciar em v√°rios aspectos do modelo e o processo de treino. Aqui est√£o alguns exemplos:

1. **Precis√£o do modelo**: A quantidade de dados pode afetar a precis√£o do modelo. Em geral, mais dados podem levar a um modelo mais preciso, pois o modelo pode aprender a capturar padr√µes mais complexos e vari√°veis.
2. **Overfitting**: Se voc√™ tiver um conjunto de dados muito pequeno, o modelo pode overfitting (aprendizagem excessiva), o que significa que o modelo se torna muito espec√≠fico para os dados de treinamento e n√£o generaliza bem para novos dados.
3. **Underfitting**: Se voc√™ tiver um conjunto de dados muito grande, o modelo pode underfitting (aprendizagem insuficiente), o que significa que o modelo n√£o consegue aprender a capturar os padr√µes mais complexos nos dados.
4. **Tempo de treinamento**: A quantidade de dados pode afetar o tempo de treinamento do modelo. Mais dados podem levar a um tempo de treinamento mais longo, pois o modelo precisa processar mais dados.
5. **Computacionalmente mais caro**: Mais dados podem ser computacionalmente mais caros para processar, especialmente se voc√™ estiver trabalhando com grandes conjuntos de dados.
6. **Regulariza√ß√£o**: A quantidade de dados pode influenciar a escolha da regulariza√ß√£o. Se voc√™ tiver um conjunto de dados pequeno, pode ser necess√°rio usar uma regulariza√ß√£o mais forte para evitar overfitting.
7. **Hyperparameter tuning**: A quantidade de dados pode influenciar a escolha dos hiperpar√¢metros do modelo. Se voc√™ tiver um conjunto de dados pequeno, pode ser necess√°rio ajustar os hiperpar√¢metros de forma mais cuidadosa para evitar overfitting.

Em resumo, a quantidade de dados que voc√™ usa para treinar um modelo de ML pode influenciar em v√°rios aspectos do modelo e do processo de treinamento, incluindo a precis√£o, overfitting, underfitting, tempo de treinamento, computacionalmente mais caro, regulariza√ß√£o e hyperparameter tuning.

## üóÉÔ∏è Pr√©-Processamento de Dados

* Tokeniza√ß√£o: dividir o texto em palavras ou tokens (e.g. utilizando o algoritmo WordPiece)
* Remo√ß√£o de stop words: remover palavras comuns como "the", "and", etc.
* Normaliza√ß√£o: normalizar a frequ√™ncia de palavras e tokens (e.g. utilizando o algoritmo TF-IDF)
* Convers√£o de texto para formato de entrada para o modelo (e.g. sequ√™ncia de tokens)

> Um tokenizer √© uma ferramenta que divide um texto em unidades menores, chamadas de tokens. Tokens podem ser palavras, s√≠labas, caracteres, etc. O tokenizer √© uma etapa importante no processamento de linguagem natural, pois permite que os modelos de linguagem trabalhem com textos de forma mais eficiente.
> Os tokenizers pr√©-treinados, como o tokenizer do GPT-2, s√£o projetados para trabalhar com textos em geral e s√£o muito eficazes em muitas situa√ß√µes. Eles s√£o tamb√©m muito f√°ceis de usar, pois voc√™ pode simplesmente carregar o tokenizer pr√©-treinado e come√ßar a trabalhar com ele.
> Para criar um tokenizer personalizado, voc√™ precisa definir as regras para dividir o texto em tokens. Isso pode ser feito utilizando bibliotecas de processamento de linguagem natural, como NLTK ou spaCy.

## üßÆ Escolha do Algoritmo ML

* Selecionar um algoritmo de machine learning adequado para o problema (e.g. BERT, RoBERTa, etc.)
* Configurar os par√¢metros do algoritmo (e.g. n√∫mero de camadas, n√∫mero de neur√¥nios, etc.)

Muito usado √© arquitectrura Transformer, Transformers s√£o uma arquitetura de rede neural que se baseia em autoencoders e √© projetada para lidar com linguagens naturais.
A biblioteca Transformers da Hugging Face oferece uma ampla gama de modelos para diversas tarefas de NLP, cada um com diferentes vantagens e aplica√ß√µes. Pode escolher o modelo que melhor se adapta √†s suas necessidades e utiliz√°-lo com facilidade gra√ßas √† interface unificada fornecida pela biblioteca.
[State-of-the-art Machine Learnin]([https://pypi.org/project/transformers/](https://huggingface.co/docs/transformers/index)

### Mas √© sempre necessario usar esses modelos pre-treinados?

N√£o √© sempre necess√°rio usar os modelos pr√©-treinados da biblioteca Transformers da Hugging Face. Embora os modelos pr√©-treinados sejam muito √∫teis e eficazes, h√° situa√ß√µes em que voc√™ pode querer treinar um modelo personalizado desde o in√≠cio.

Aqui est√£o algumas situa√ß√µes em que voc√™ pode querer treinar um modelo personalizado:

1. **Tarefas espec√≠ficas**: Se voc√™ est√° trabalhando em uma tarefa espec√≠fica que requer um modelo de linguagem com habilidades √∫nicas, voc√™ pode querer treinar um modelo personalizado desde o in√≠cio.
2. **Dados limitados**: Se voc√™ tem um conjunto de dados limitado, voc√™ pode n√£o ter acesso a um conjunto de dados grande o suficiente para treinar um modelo pr√©-treinado. Nesse caso, voc√™ pode querer treinar um modelo personalizado desde o in√≠cio.
3. **Requisitos de performance**: Se voc√™ tem requisitos de performance espec√≠ficos, como precis√£o ou velocidade, voc√™ pode querer treinar um modelo personalizado desde o in√≠cio para atender a esses requisitos.
4. **Propriedade intelectual**: Se voc√™ est√° trabalhando em um projeto que requer propriedade intelectual, voc√™ pode querer treinar um modelo personalizado desde o in√≠cio para evitar a depend√™ncia de modelos pr√©-treinados.
5. **Aprendizado cont√≠nuo**: Se voc√™ est√° trabalhando em um projeto que requer aprendizado cont√≠nuo, voc√™ pode querer treinar um modelo personalizado desde o in√≠cio para adaptar-se √†s mudan√ßas nos dados e nos requisitos.

No entanto, √© importante notar que treinar um modelo personalizado desde o in√≠cio pode ser um processo mais complexo e demorar mais tempo do que utilizar um modelo pr√©-treinado. Al√©m disso, os modelos pr√©-treinados podem ser muito eficazes e podem atender √†s suas necessidades em muitas situa√ß√µes.

## üèãÔ∏è Etapas de Treinamento

* Treinamento: repetir as etapas de treino v√°rias vezes, ajustando os par√¢metros do modelo para minimizar a perda
* Valida√ß√£o: avaliar o desempenho do modelo no conjunto de valida√ß√£o para evitar overfitting
* Teste: avaliar o desempenho do modelo no conjunto de teste para avaliar sua generaliza√ß√£o

## üèãÔ∏è Etapas no Treino

1. **Forward Pass**: o modelo processa o input (e.g. uma frase) e produz uma sa√≠da (e.g. uma sequ√™ncia de tokens)
2. **C√°lculo da Perda**: o modelo calcula a diferen√ßa entre a sa√≠da prevista e a sa√≠da real (e.g. a perda de cross-entropy)
3. **Backward Pass**: o modelo ajusta seus par√¢metros internos para reduzir a perda (e.g. ajustando os pesos e bias da rede neural)
4. **Atualiza√ß√£o dos Par√¢metros**: o modelo atualiza seus par√¢metros internos com base na diferen√ßa entre a sa√≠da prevista e a sa√≠da real

## üíæ Ficheiros finais treinados

* O modelo treinado produz ficheiros de sa√≠da que podem ser usados para:
	+ Gerar texto com base em um input (e.g. um prompt)
	+ Realizar tarefas de processamento de linguagem natural (e.g. classifica√ß√£o de texto, gera√ß√£o de resumo, etc.)
	+ Treinar modelos adicionais para tarefas espec√≠ficas

## üíæ uma LLM/SLM depois de treinadas melhoram com a utilia√ß√£o?

Sim mas depende de como ela √© treinada e utilizada. Aqui est√£o algumas raz√µes pelas quais uma LLM/SLM pode melhorar com a utiliza√ß√£o:

- **Aprendizagem cont√≠nua**: Muitas LLMs/SLMs s√£o treinadas com um conjunto de dados inicial, mas podem aprender a partir de **novos dados** e **feedback* durante a utiliza√ß√£o. Isso permite que elas atualizem suas representa√ß√µes de linguagem e melhorem suas habilidades.-
-  **Fine-tuning**: Algumas LLMs/SLMs podem ser fine-tuned para um conjunto espec√≠fico de tarefas ou dom√≠nios. Isso envolve ajustar os par√¢metros da rede neural para melhor se adaptar √†s necessidades espec√≠ficas da tarefa ou dom√≠nio. A fine-tuning pode melhorar significativamente as habilidades da LLM/SLM.
- **Adaptabilidade**: Algumas LLMs/SLMs s√£o projetadas para serem adapt√°veis, o que significa que elas podem aprender a partir de novos dados e feedback e se adaptar √†s mudan√ßas no ambiente.
- **Feedback**: O feedback do usu√°rio pode ser utilizado para melhorar a performance da LLM/SLM. Por exemplo, se um usu√°rio corrigir erros ou fornecer feedback positivo ou negativo, a LLM pode aprender a partir disso e melhorar suas habilidades.
- **Aumento da complexidade**: Algumas LLMs/SLMs podem ser projetadas para lidar com linguagens mais complexas ou dom√≠nios mais espec√≠ficos. A utiliza√ß√£o pode ajudar a melhorar a habilidade da LLM em lidar com essas linguagens ou dom√≠nios.

No entanto, √© importante notar que a melhoria da LLM/SLM com a utiliza√ß√£o depende de v√°rios fatores, incluindo:

* A qualidade e a quantidade de dados utilizados para treinar e fine-tune a LLM/SLM.
* A habilidade do usu√°rio em fornecer feedback e guiar a LLM/SLM para melhorar.
* A capacidade da LLM/SLM em aprender a partir de novos dados e feedback.
* A complexidade e a natureza da tarefa ou dom√≠nio que a LLM/SLM est√° sendo utilizada.

## ‚ùì Como usar esses 'ficheiros'

Existem v√°rias op√ß√µes para alojar os ficheiros treinados de sa√≠da para uso como API. Aqui est√£o algumas op√ß√µes:

- **Servidor pr√≥prio**: voc√™ pode hospedar os ficheiros em um servidor pr√≥prio, utilizando tecnologias como Apache, Nginx ou IIS. Isso permite que voc√™ tenha controle total sobre a infraestrutura e a seguran√ßa.
- **Servidores de nuvem**: voc√™ pode utilizar servi√ßos de nuvem como AWS S3, Google Cloud Storage ou Microsoft Azure Blob Storage para armazenar e servir os ficheiros. Esses servi√ßos oferecem escalabilidade, seguran√ßa e facilidade de uso.
- **Plataformas de API**: voc√™ pode utilizar plataformas de API como AWS API Gateway, Google Cloud Endpoints ou Microsoft Azure API Management para criar e gerenciar APIs. Essas plataformas oferecem recursos como autentica√ß√£o, autoriza√ß√£o e monitoramento.
- **Servi√ßos de armazenamento de dados**: voc√™ pode utilizar servi√ßos de armazenamento de dados como MongoDB, Cassandra ou PostgreSQL para armazenar e servir os ficheiros. Esses servi√ßos oferecem escalabilidade, seguran√ßa e facilidade de uso.
- **Servi√ßos de computa√ß√£o em nuvem**: voc√™ pode utilizar servi√ßos de computa√ß√£o em nuvem como AWS Lambda, Google Cloud Functions ou Microsoft Azure Functions para executar o modelo de linguagem e servir os resultados como API. Esses servi√ßos oferecem escalabilidade, seguran√ßa e facilidade de uso.

### Quando escolher uma op√ß√£o, considere fatores como:

* Necessidade de recursos (harware) proderosos para ter uma boa resposta! Modelos que usam 4 bili√µes de parametros* (LLM) em treino precisam de um CPU Intel Core i9-11900K ou um AMD Ryzen 9 5900X, 32Gb Ram e  NVIDIA GeForce RTX 3080 ou um AMD Radeon RX 6800 XT
* Escalabilidade: como o seu modelo de linguagem ir√° crescer, voc√™ precisar√° de uma solu√ß√£o que possa lidar com o aumento do tr√°fego e do armazenamento de dados.
* Seguran√ßa: voc√™ precisar√° garantir que os ficheiros treinados de sa√≠da sejam protegidos contra acesso n√£o autorizado e que a API seja segura para uso.
* Custos: voc√™ precisar√° considerar os custos associados √† escolha da op√ß√£o, incluindo custos de armazenamento, processamento e transfer√™ncia de dados.
* Facilidade de uso: voc√™ precisar√° considerar a facilidade de uso e a documenta√ß√£o da op√ß√£o escolhida.

> [!NOTE]
> Os par√¢metros de um modelo de linguagem s√£o as vari√°veis que s√£o ajustadas durante o treinamento do modelo para melhorar sua capacidade de prever a sa√≠da correta para uma entrada. Mais par√¢metros significam que o modelo tem mais capacidade para aprender e generalizar a partir dos dados de treinamento.
> 100M a 1B (100 milh√µes a 1 bilh√£o) de par√¢metros: Esses s√£o os par√¢metros t√≠picos de um SLM que √© treinado para tarefas de processamento de linguagem natural, como classifica√ß√£o de texto, sentiment analysis e gera√ß√£o de texto.
10M a 100M (10 milh√µes a 100 milh√µes) de par√¢metros: Esses s√£o os par√¢metros t√≠picos de um SLM que √© treinado para tarefas mais espec√≠ficas, como reconhecimento de entidade ou gera√ß√£o de resumo.
1M a 10M (1 milh√£o a 10 milh√µes) de par√¢metros: Esses s√£o os par√¢metros t√≠picos de um SLM que √© treinado para tarefas mais simples, como classifica√ß√£o de texto ou sentiment analysis.

###  Hugging Face 

√© um servi√ßo que fornece uma plataforma para desenvolvedores e cientistas de dados trabalhar com modelos de linguagem e outros tipos de modelos de aprendizado de m√°quina. Eles oferecem uma variedade de recursos, incluindo:

* Um reposit√≥rio de modelos de linguagem pr√©-treinados, incluindo modelos como BERT, RoBERTa e XLNet.
* Uma plataforma para treinar e testar modelos de linguagem.
* Uma API para integrar modelos de linguagem em aplicativos e servi√ßos.
* Ferramentas para processamento de linguagem natural, incluindo tokeniza√ß√£o, paralelismo e gera√ß√£o de texto.

Hugging Face tamb√©m fornece uma variedade de servi√ßos, incluindo:

* Hugging Face Hub: um reposit√≥rio de modelos de linguagem pr√©-treinados e treinados.
* Hugging Face Transformers: uma biblioteca de transformadores de linguagem natural.
* Hugging Face Datasets: uma plataforma para armazenar e compartilhar conjuntos de dados de linguagem natural.

Em resumo, Hugging Face √© um servi√ßo que fornece uma plataforma para desenvolvedores e cientistas de dados trabalhar com modelos de linguagem e outros tipos de modelos de aprendizado de m√°quina. Eles oferecem uma variedade de recursos e servi√ßos para ajudar a desenvolver e implementar aplicativos e servi√ßos que utilizam modelos de linguagem.
